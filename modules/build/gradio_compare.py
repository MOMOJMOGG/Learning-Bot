from chromadb import PersistentClient
from dotenv import load_dotenv
import gradio as gr
import openai
import os
import pandas as pd
import sqlite3
import tempfile

# è®€å– .env æª”æ¡ˆ
load_dotenv()

# === è¨­å®šæŸ¥è©¢èªå¥èˆ‡åƒæ•¸ ===
QUERY_TEXT = "æˆ‘æƒ³æå‡å¥åº·èˆ‡é«”æ…‹"
CHROMA_DIR = "./chroma_db"
COLLECTION_CHROMBA = "sat_courses"
COLLECTION_OPENAI  = "sat_courses_openai"
DB_FILE = "search_cache.db"

# åˆå§‹åŒ– OpenAI API
openai.api_key = os.environ.get("OPAI_API_KEY")
client = PersistentClient(path=CHROMA_DIR)

# === DB åˆå§‹åŒ– ===
def init_db():
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute('''
        CREATE TABLE IF NOT EXISTS cache (
            query TEXT PRIMARY KEY,
            table_a TEXT,
            table_b TEXT
        )
    ''')
    conn.commit()
    conn.close()
    
# === æŸ¥è©¢å¿«å– ===
def load_from_cache(query):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("SELECT table_a, table_b FROM cache WHERE query=?", (query,))
    row = c.fetchone()
    conn.close()
    if row:
        return row[0], row[1]
    return None

def save_to_cache(query, html_a, html_b):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("REPLACE INTO cache (query, table_a, table_b) VALUES (?, ?, ?)",
              (query, html_a, html_b))
    conn.commit()
    conn.close()

def get_query_history():
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("SELECT query FROM cache ORDER BY rowid DESC LIMIT 20")
    rows = c.fetchall()
    conn.close()
    return [row[0] for row in rows]

# === æ¨¡å‹æŸ¥è©¢ ===
def get_openai_embedding(text: str) -> list:
    response = openai.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return response.data[0].embedding

def query_collection_html_and_csv(collection, query_text=None, query_embedding=None, use_embedding=False):
    if use_embedding:
        result = collection.query(query_embeddings=[query_embedding], n_results=3)
    else:
        result = collection.query(query_texts=[query_text], n_results=3)

    courses = result["metadatas"][0]
    distances = result["distances"][0]

    table = {
        "æ¬„ä½": ["æ¨™é¡Œ", "è¬›å¸«", "åˆ†é¡", "å¹³å°", "åƒ¹æ ¼", "è©•åˆ†", "èª²ç¨‹é€£çµ", "ç›¸ä¼¼åº¦"]
    }

    for i, (meta, dist) in enumerate(zip(courses, distances), 1):
        link_html = f'<a href="{meta["link"]}" target="_blank">{meta["link"]}</a>'
        table[f"èª²ç¨‹{i}"] = [
            meta["title"],
            meta["teacher"],
            meta["category"],
            meta["platform"],
            meta["price"],
            meta["rating"],
            link_html,
            f"{dist:.4f}"
        ]

    df = pd.DataFrame(table)
    df_csv = df.copy()
    
    # æ‰¾å‡ºæ‰€æœ‰èª²ç¨‹æ¬„ä½ï¼ˆé™¤äº†ç¬¬ä¸€æ¬„ã€Œæ¬„ä½ã€ï¼‰
    course_columns = [col for col in df_csv.columns if col != "æ¬„ä½"]

    # æ›¿æ›ã€Œèª²ç¨‹é€£çµã€åˆ—ç‚ºç´”ç¶²å€
    for i, col in enumerate(course_columns):
        df_csv.loc[df_csv["æ¬„ä½"] == "èª²ç¨‹é€£çµ", col] = courses[i]["link"]

    # å„²å­˜æˆæš«å­˜ CSV æª”æ¡ˆ
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".csv", mode='w', newline='', encoding='utf-8')
    df_csv.to_csv(tmp.name, index=False)
    return df.to_html(escape=False, index=False), tmp.name

# === ä¸»æŸ¥è©¢æµç¨‹ ===
def search_courses(query_text):
    cached = load_from_cache(query_text)
    if cached:
        return cached[0], cached[1], None, None, gr.update(choices=get_query_history())

    collection_transformer = client.get_collection(name=COLLECTION_CHROMBA)
    collection_openai = client.get_collection(name=COLLECTION_OPENAI)

    result_a = query_collection_html_and_csv(collection_transformer, query_text=query_text, use_embedding=False)
    embedding_b = get_openai_embedding(query_text)
    result_b = query_collection_html_and_csv(collection_openai, query_embedding=embedding_b, use_embedding=True)

    html_a, csv_a = result_a
    html_b, csv_b = result_b
    
    save_to_cache(query_text, html_a, html_b)
    return html_a, html_b, csv_a, csv_b, gr.update(choices=get_query_history())

# === é»é¸æ­·å²æŸ¥è©¢é …ç›® ===
def reuse_history_item(selected_query):
    return search_courses(selected_query)

# === åˆå§‹åŒ–è³‡æ–™åº« ===
init_db()

# === Gradio ä»‹é¢ ===
with gr.Blocks(title="èª²ç¨‹èªæ„æŸ¥è©¢æ¯”è¼ƒå·¥å…· (å«å¿«å–èˆ‡ CSV ä¸‹è¼‰)") as demo:
    gr.Markdown("## ğŸ“ èª²ç¨‹èªæ„æŸ¥è©¢å·¥å…·ï¼šæ¯”è¼ƒå…©ç¨®æ¨¡å‹æ¨è–¦çµæœ")
    with gr.Row():
        query_input = gr.Textbox(label="è¼¸å…¥æŸ¥è©¢å¥å­", placeholder="ä¾‹å¦‚ï¼šæˆ‘æƒ³å­¸AIè‡ªå‹•åŒ–")
        search_button = gr.Button("æŸ¥è©¢")

    with gr.Row():
        table1 = gr.HTML(label="ğŸ“˜ SentenceTransformer æ¨¡å‹æŸ¥è©¢çµæœ")
        table2 = gr.HTML(label="ğŸ¤– OpenAI æ¨¡å‹æŸ¥è©¢çµæœ")

    with gr.Row():
        csv1 = gr.File(label="ğŸ“¥ ä¸‹è¼‰ SentenceTransformer æ¨¡å‹çµæœ", interactive=False)
        csv2 = gr.File(label="ğŸ“¥ ä¸‹è¼‰ OpenAI æ¨¡å‹çµæœ", interactive=False)
        
    with gr.Row():
        gr.Markdown("### ğŸ” æ­·å²æŸ¥è©¢")
        history_list = gr.Dropdown(choices=get_query_history(), label="éå»æŸ¥è©¢å¥å­")
        
    search_button.click(
        fn=search_courses,
        inputs=[query_input],
        outputs=[table1, table2, csv1, csv2, history_list]
    )

    history_list.change(
        fn=reuse_history_item,
        inputs=[history_list],
        outputs=[table1, table2, csv1, csv2, history_list]
    )

# å•Ÿå‹•æœå‹™
if __name__ == "__main__":
    demo.launch()